Tweentyfifth = quantile(R, probs = 0.25, na.rm = TRUE),
Fiftith = quantile(R, probs = 0.5, na.rm = TRUE),
Seventyfifth = quantile(R, probs = 0.75, na.rm = TRUE),
Ninetith = quantile(R, probs = 0.9, na.rm = TRUE),
Titles = n_distinct(titleno),
Observations = NROW(country),
Editions = n_distinct(asin))
#Read in dataDesKript2.RDS
dataDesKript2 <-readRDS("dataDesKript2.RDS")
# Merge Dataframes
DataDes <- rbind(dataDesKript, dataDesKript2)
# Transform Dataframe into a clearer schema
DataDesTest <- t(DataDes)
colnames(DataDesTest) <- rownames(DataDes)
DataDescriptive <- as.data.frame(DataDesTest)
colnames(DataDescriptive) <- unlist(DataDescriptive[1,])
DataDescriptivefinal <- DataDescriptive[-1,]
# Change Row Names
row.names(DataDescriptivefinal) = c("Price", "Star rating", "Sales rank", "Number of ratings", "10th", "25th", "50th", "75th", "90th", "Titles", "Observations", "Editions")
# Kable-Function to create an attractive overview
DataDescriptivefinal %>%
kbl(col.names = c("CA" = "Canada", "GB" = "Great Britain", "US" = "United States", "All" = "All"), caption = "Group Rows") %>%
kable_paper("striped", full_width = TRUE) %>%
pack_rows("Star rating percentiles", 5, 9) %>%
pack_rows("", 10, 12)
DataDescriptiveJournals <- readRDS("DataDescriptiveJournals.RDS")
# Kable-Function to create a table
DataDescriptiveJournals %>%
kbl(col.names = c("CA" = "Canada", "GB" = "Great Britain", "US" = "United States", "All" = "All"), caption = "Group Rows") %>%
kable_paper("striped", full_width = TRUE) %>%
pack_rows("Star rating percentiles", 5, 9) %>%
pack_rows("", 10, 12)
dataReviewRec <- data %>%
filter(drecommended == 1 & cno == 3) %>%
summarise(AVGPrice = mean(pamzn),
AVGSalesRank = mean(rank, na.rm = TRUE),
AVGCR = mean(R, na.rm = TRUE))
#U.S. data reviewed by the New York Times but not recommended
dataReviewNRec <- data %>%
filter(drecommended == 0 & DNYT == 1 & cno == 3) %>%
summarise(AVGPrice = mean(pamzn),
AVGSalesRank = mean(rank, na.rm = TRUE),
AVGCR = mean(R, na.rm = TRUE))
#U.S. data not recommended or reviewed by The New York Times.
dataReviewNNYT <- data %>%
filter(drecommended == 0 & DNYT == 0 & cno == 3) %>%
summarise(AVGPrice = mean(pamzn),
AVGSalesRank = mean(rank, na.rm = TRUE),
AVGCR = mean(R, na.rm = TRUE))
dataNYTPrice <- data.frame(Price = c(dataReviewRec$AVGPrice, dataReviewNRec$AVGPrice, dataReviewNNYT$AVGPrice), SalesRank = c(dataReviewRec$AVGSalesRank, dataReviewNRec$AVGSalesRank, dataReviewNNYT$AVGSalesRank), Category = c("Recommended", "Not Recommended", "Not NYT"))
f3 <- dataNYTPrice %>%
ggplot() +
geom_histogram(aes(y = Price, x = Category,  fill = Category), stat = "identity", width = 0.3) +
geom_text(aes(x = Category, y = Price - 1.5, label = round(Price, 2)), color = "white", size = 5) +
coord_flip() +
scale_x_discrete(expand = c(0, 1)) +
theme_bw() +
ylim(0, 21) +
# geom_bar(aes(y = SR, x = Category,  fill = Category), position = "dodge", stat = "identity")
scale_fill_manual("", values = c("Not NYT" = "deepskyblue", "Not Recommended" = "darkorchid2", "Recommended" = "blue3")) +
labs(title = "Differences in mean prices (US Data only)",
x = "",
y = "Price in USD") +
guides(fill = guide_legend(reverse = TRUE)) +
theme(legend.position = "bottom",
axis.text.y=element_blank(),
panel.grid.minor=element_blank(),plot.background=element_blank())
#Plot 2: Mean Sales Ranks
f4 <- readRDS("f4.RDS")
#Side by side plot
grid.arrange(f3, f4, ncol = 2)
data$starRating1_3 <- ifelse(data$R >= 1 & data$R < 3, 1, 0)
data$starRating3_4 <- ifelse(data$R >= 3 & data$R < 4, 1, 0)
data$starRating4_5 <- ifelse(data$R >= 4 & data$R < 5, 1, 0)
dataCR1_3 <- data %>%
filter(data$starRating1_3 == 1 & DALL == 0 & cno == 3) %>%
summarise(AVGPrice = mean(pamzn),
AVGSalesRank = mean(rank, na.rm = TRUE))
data$DALL <- ifelse(data$DBG == 1 | data$DCHI == 1 | data$DLAT == 1 | data$DWAPO == 1 | data$DWSJ == 1 | data$DNYT == 1 , 1, 0)
data$starRating1_3 <- ifelse(data$R >= 1 & data$R < 3, 1, 0)
data$starRating3_4 <- ifelse(data$R >= 3 & data$R < 4, 1, 0)
data$starRating4_5 <- ifelse(data$R >= 4 & data$R < 5, 1, 0)
dataCR1_3 <- data %>%
filter(data$starRating1_3 == 1 & DALL == 0 & cno == 3) %>%
summarise(AVGPrice = mean(pamzn),
AVGSalesRank = mean(rank, na.rm = TRUE))
dataCR3_4 <- data %>%
filter(data$starRating3_4 == 1 & DALL == 0 & cno == 3) %>%
summarise(AVGPrice = mean(pamzn),
AVGSalesRank = mean(rank, na.rm = TRUE))
dataCR4_5 <- data %>%
filter(data$starRating4_5 == 1 & DALL == 0 & cno == 3) %>%
summarise(AVGPrice = mean(pamzn),
AVGSalesRank = mean(rank, na.rm = TRUE))
dataCRPrice <- data.frame(Price = c(dataCR1_3$AVGPrice, dataCR3_4$AVGPrice, dataCR4_5$AVGPrice), SalesRank = c(dataCR1_3$AVGSalesRank, dataCR3_4$AVGSalesRank, dataCR4_5$AVGSalesRank), Category = c("1-3 stars", "3-4 Stars", "more than 4 stars"))
f5 <- dataCRPrice %>%
ggplot() +
geom_histogram(aes(y = Price, x = Category,  fill = Category), stat = "identity", width = 0.3) +
geom_text(aes(x = Category, y = Price - 1.5, label = round(Price, 2)), color = "white", size = 5) +
coord_flip() +
scale_x_discrete(expand = c(0, 1)) +
theme_bw() +
ylim(0, 21) +
scale_fill_manual("", values = c("1-3 stars" = "deepskyblue", "3-4 Stars" = "darkorchid2", "more than 4 stars" = "blue3")) +
labs(title = "Differences in Mean Prices (U.S. Data Only)",
x = "",
y = "Price in USD") +
guides(fill = guide_legend(reverse = TRUE)) +
theme(legend.position = "bottom",
axis.text.y=element_blank(),
panel.grid.minor=element_blank(),plot.background=element_blank())
#Plot 2: Mean Sales Ranks
f6 <- readRDS("f6.RDS")
grid.arrange(f5, f6, ncol = 2)
dataTop10000 <- data %>%
filter(cno == 3 & rank <= 10000) %>%
group_by(ddate) %>%
summarise(price = mean(pamzn),
Group = "Top 10.000")
dataTop1000 <- data %>%
filter(cno == 3 & rank <= 1000) %>%
group_by(ddate) %>%
summarise(price = mean(pamzn),
Group = "Top 1.000")
dataTop <- rbind(dataTop10000, dataTop1000)
dataTop %>%
ggplot() +
theme_bw() +
geom_line(aes(x = ddate, color = Group,  y = price), stat = "identity", width = 0.3,  position = position_dodge()) +
scale_color_manual("Category", values = c("Top 10.000" = "deepskyblue", "Top 1.000" = "red"))  +
labs(title = "Differences in mean Sales Ranks (US Data only)",
x = "Date",
y = "Mean Price in USD")
dataLite <- data[sample(nrow(data), size = 100000, replace = TRUE),]
regFirstStep <- lm(rank ~ pamzn + R, data = dataLite)
summary(regFirstStep)
set.seed(123)
dataLite <- data[sample(nrow(data), size = 100000, replace = TRUE),]
regFirstStep <- lm(rank ~ pamzn + R, data = dataLite)
summary(regFirstStep)
dataLite <- data[sample(nrow(data), size = 100000, replace = TRUE),]
regFirstStep <- lm(rank ~ pamzn + R, data = dataLite)
summary(regFirstStep)
set.seed(123)
dataLite <- data[sample(nrow(data), size = 100000, replace = TRUE),]
regFirstStep <- lm(rank ~ pamzn + R, data = dataLite)
summary(regFirstStep)
set.seed(123)
dataLite <- data[sample(nrow(data), size = 100000, replace = TRUE),]
regFirstStep <- lm(rank ~ pamzn + R, data = dataLite)
summary(regFirstStep)
set.seed(123)
dataLite <- data[sample(nrow(data), size = 100000, replace = TRUE),]
regFirstStep <- lm(rank ~ pamzn + R, data = dataLite)
summary(regFirstStep)
set.seed(123)
dataLite <- data[sample(nrow(data), size = 100000, replace = TRUE),]
regFirstStep <- lm(rank ~ pamzn + R, data = dataLite)
summary(regFirstStep)
library(fixest)
regRSE <- feols(rank ~ pamzn + R, vcov = "hetero", data = dataLite)
summary(regRSE)
library(modelsummary)
regFE <- feols(rank ~ pamzn | canum, vcov = "hetero", data = dataLite)
regWFE <- lm(rank ~ pamzn, data = dataLite)
modelsummary(list(regWFE, regFE), statistic = "({std.error})", coef_rename = c("pamzn" = "Amazon Price"))
regFE <- feols(rank ~ pamzn + R | canum, vcov = "hetero", data = dataLite)
regWFE <- lm(rank ~ pamzn + R, data = dataLite)
modelsummary(list(regWFE, regFE), statistic = "({std.error})", coef_rename = c("pamzn" = "Amazon Price"))
regFE <- feols(rank ~ pamzn  | canum, vcov = "hetero", data = dataLite)
regWFE <- lm(rank ~ pamzn, data = dataLite)
modelsummary(list(regWFE, regFE), statistic = "({std.error})", coef_rename = c("pamzn" = "Amazon Price"))
dataUS <- data %>%
filter(cno == 3) %>%
arrange(canum, ddate)
library(fixest)
#Create the regression `reg2`
reg2 <- feols(lrank ~ L1.lrank + lpamzn + lreview + lR  + dnytpost1_3 + dnytpost6_3 +  dnytpost10_3 + dothpost_3 + dothpost10_3 + dnytpostpre_1 + dnytpostpre_2 + dnytpostpre_3 + dothpostpre_1 + dothpostpre_2 + dothpostpre_3 + dnytpost1r_3 + dnytpost6r_3 + dnytpost10r_3 + dnytpostprer_1 + dnytpostprer_2 + dnytpostprer_3 + epos + epos2 + epos3 + eneg + eneg2 + eneg3 | ano, vcov = "hetero", data = dataUS)
reg3 <- feols(lrank ~ L1.lrank + lpamzn + lreview + lR + lrR + dnytpost1_3 + dnytpost6_3 + dnytpost10_1 + dnytpost10_2 +  dnytpost10_3 + dothpost_1 + dothpost_2 + dothpost_3 + dothpost10_1 + dothpost10_2 + dothpost10_3 + dnytpostpre_1 + dnytpostpre_2 + dnytpostpre_3 + dothpostpre_1 + dothpostpre_2 + dothpostpre_3 + dnytpost1r_3 + dnytpost6r_3 + dnytpost10r_3 + dnytpostprer_1 + dnytpostprer_2 + dnytpostprer_3 + epos + epos2 + epos3 + eneg + eneg2 + eneg3 | ano, vcov = "hetero", data = dataUS)
#< task_notest
reg1 <- feols(lrank ~ L1.lrank + lpamzn + lreview + lR + DNYT + DNYT0 + DNYT1 + DNYT2 + DNYT3 +DNYT4 + DNYT5 + DNYT6 + DNYT7 + DNYT8 + DNYT9 + DNYT10 + DNYT11 + DNYT12 + DNYT13 +DNYT14 + DNYT15 +DNYT16 + DNYT17 +DNYT18 +DNYT19 + DNYT20 + DNYT21 + DNYT22 + DNYT23 + DNYT24 + DNYT25 + DNYT26 + DNYT27 + DNYT28 + DNYT29 + DNYT30 + DNYT31 + DNYT32 + DNYT33 + DNYT34 + DNYT35 + DNYT36 + DNYT37 + DNYT38 + DNYT39 +DNYT40 + DNYTm1 + DNYTm2 + DNYTm3 + DNYTm4 + DNYTm5 + DNYTm6 + DNYTm7 + DNYTm8 + DNYTm9 + DNYTm10 + DNYTm11 + DNYTm12 + DNYTm13 + DNYTm14 + DNYTm15 + DNYTm16 + DNYTm17 + DNYTm18 + DNYTm19 + DNYTm20 + DOTH0 + DOTH1 + DOTH2 + DOTH3 +DOTH4 + DOTH5 + DOTH6 + DOTH7 + DOTH8 + DOTH9 + DOTH10 + DOTH11 + DOTH12 + DOTH13 + DOTH14 + DOTH15 +DOTH16 + DOTH17 + DOTH18 + DOTH19 + DOTH20 + DOTH21 + DOTH22 + DOTH23 + DOTH24 + DNYT25 + DNYT26 + DNYT27 + DNYT28 + DNYT29 + DNYT30 + DNYT31 + DNYT32 + DNYT33 + DNYT34 + DNYT35 + DNYT36 + DNYT37 + DNYT38 + DOTH39 +DOTH40 + DOTHm1 + DOTHm2 + DOTHm3 + DOTHm4 + DOTHm5 + DOTHm6 + DOTHm7 + DOTHm8 + DOTHm9 + DOTHm10 + DOTHm11 + DOTHm12 + DOTHm13 + DOTHm14 + DOTHm15 + DOTHm16 + DOTHm17 + DOTHm18 + DOTHm19 + DOTHm20 + epos + epos2 + epos3 + eneg + eneg2 + eneg3 | canum, vcov = "hetero", data = dataUS)
reg4 <- feols(lrank ~ L1.lrank + lpamzn + lreview + lR  + dnytpost1_1 + dnytpost1_2 + dnytpost1_3 + dnytpost6_1 + dnytpost6_2 + dnytpost6_3 + dnytpost10_1 + dnytpost10_2 +  dnytpost10_3 + dothpost_1 + dothpost_2 + dothpost_3 + dothpost10_1 + dothpost10_2 + dothpost10_3 + dnytpostpre_1 + dnytpostpre_2 + dnytpostpre_3 + dothpostpre_1 + dothpostpre_2 + dothpostpre_3 + dnytpost1r_1 + dnytpost1r_2 + dnytpost1r_3 + dnytpost6r_1 + dnytpost6r_2 + dnytpost6r_3 + dnytpost10r_1 + dnytpost10r_2 + dnytpost10r_3 + dnytpostprer_1 + dnytpostprer_2 + dnytpostprer_3 + epos + epos2 + epos3 + eneg + eneg2 + eneg3 | canum, vcov = "hetero", data = data)
reg5 <- feols(lrank ~ L1.lrank + lpamzn + lreview + lR + lrR + dnytpost1_1 + dnytpost1_2 + dnytpost1_3 + dnytpost6_1 + dnytpost6_2 + dnytpost6_3 + dnytpost10_1 + dnytpost10_2 +  dnytpost10_3 + dothpost_1 + dothpost_2 + dothpost_3 + dothpost10_1 + dothpost10_2 + dothpost10_3 + dnytpostpre_1 + dnytpostpre_2 + dnytpostpre_3 + dothpostpre_1 + dothpostpre_2 + dothpostpre_3 + dnytpost1r_1 + dnytpost1r_2 + dnytpost1r_3 + dnytpost6r_1 + dnytpost6r_2 + dnytpost6r_3 + dnytpost10r_1 + dnytpost10r_2 + dnytpost10r_3 + dnytpostprer_1 + dnytpostprer_2 + dnytpostprer_3 + epos + epos2 + epos3 + eneg + eneg2 + eneg3 | canum, vcov = "hetero", data = data)
#>
RegTable <- modelsummary(list(reg1, reg2, reg3, reg4, reg5), statistic = "({std.error})", coef_omit = "DOTH|DNYT|epos|eneg|postpre|_1|_2", coef_rename = c("L1.lrank" = "Lagged log sales rank", "lpamzn" = "Log Amazon price", "lreview" = "Number of ratings", "lR" = "log star rating","lrR" = "log number of ratings x log stars", "dnytpost1_3" = "NYT: 0-5 days", "dnytpost6_3" = "NYT: 6-10 days", "dnytpost10_3" = "NYT: 11-20 days", "dnytpost1r_3" = "NYT Rec: 0-5 days", "dnytpost6r_3" = "NYT Rec: 6-10 days", "dnytpost10r_3" = "NYT Rec: 11-20 days", "dothpost_3" = "OTH: 1-10 days", "dothpost10_3" = "OTH: 11-20 days"))
RegTable
reg6 <- feols(lpamzn ~ lrank + lreview + lR  + dnytpost1_3 + dnytpost6_3 + lrR + dnytpost10_3 + dothpost_3 + dothpost10_3 + dnytpostpre_1 + dnytpostpre_2 + dnytpostpre_3 + dothpostpre_1 + dothpostpre_2 + dothpostpre_3 + dnytpost1r_3 + dnytpost6r_3 + dnytpost10r_3 + dnytpostprer_1 + dnytpostprer_2 + dnytpostprer_3 + epos + epos2 + epos3 + eneg + eneg2 + eneg3 | canum, vcov = "hetero", data = dataUS)
reg7 <- feols(lpamzn ~ lrank + lreview + lR  + dnytpost1_3 + dnytpost6_3 + dnytpost10_3 + dothpost_3 + dothpost10_3 + dnytpostpre_1 + dnytpostpre_2 + dnytpostpre_3 + dothpostpre_1 + dothpostpre_2 + dothpostpre_3 + dnytpost1r_3 + dnytpost6r_3 + dnytpost10r_3 + dnytpostprer_1 + dnytpostprer_2 + dnytpostprer_3 + epos + epos2 + epos3 + eneg + eneg2 + eneg3 | canum, vcov = "hetero", data = dataUS)
RegTable2 <- modelsummary(list(reg6, reg7), statistic = "({std.error})", coef_omit = "DOTH|DNYT|epos|eneg|postpre|_1|_2", coef_rename = c("lpamzn" = "Log Amazon price", "lreview" = "Number of ratings", "lR" = "log star rating","lrR" = "log number of ratings x log stars", "dnytpost1_3" = "NYT: 0-5 days", "dnytpost6_3" = "NYT: 6-10 days", "dnytpost10_3" = "NYT: 11-20 days", "dnytpost1r_3" = "NYT Rec: 0-5 days", "dnytpost6r_3" = "NYT Rec: 6-10 days", "dnytpost10r_3" = "NYT Rec: 11-20 days", "dothpost_3" = "OTH: 1-10 days", "dothpost10_3" = "OTH: 11-20 days"))
RegTable2
dataESNYT <- data %>%
filter(cno == 3 & NYT_elapse >= -20 & NYT_elapse <= 40) %>%
group_by(titleno) %>%
summarize(Sum_observations = n())
nrow(dataESNYT)
sum(dataESNYT$Sum_observations)
dataESOTH <- data %>%
filter(cno == 3 & OTH_elapse >= -20 & OTH_elapse <= 40) %>%
group_by(titleno) %>%
summarize(Sum_observations = n())
nrow(dataESOTH)
sum(dataESOTH$Sum_observations)
reg7 <- feols(lrank ~ L1.lrank + lpamzn + lreview + lR | canum, vcov = "hetero", data = dataUS)
reg7$residuals <- reg7$residuals - mean(reg7$residuals[which(dataUS$NYT_elapse == -1)])
reg7_agg <- aggregate(reg7$residuals, by = list(dataUS$NYT_elapse), FUN = mean)
colnames(reg7_agg) <- c("NYT_elapse", "Avg.Sales.rank")
reg7_agg <- reg7_agg %>%
mutate(Max95 = Avg.Sales.rank + (1.96*sd(Avg.Sales.rank)/ sqrt(length(reg7))),
Min95 = Avg.Sales.rank - (1.96*sd(Avg.Sales.rank) / sqrt(length(reg7))))
ESNYT <- ggplot(reg7_agg, aes(x = NYT_elapse, y = Avg.Sales.rank)) +
geom_line() +
ggtitle("Event Study - New York Times") +
scale_x_continuous(breaks = seq(-20, 40, by = 10), limits = c(-20, 40)) +
geom_line(aes(y = Max95), linetype = "dashed") +
geom_line(aes(y = Min95), linetype = "dotted") +
geom_vline(xintercept = -1, color = "red", size = 0.5) +
scale_y_reverse() +
ylim(0.3, -0.6) +
theme_minimal()
ESNYT
ESNYT <- ggplot(reg7_agg, aes(x = NYT_elapse, y = Avg.Sales.rank)) +
geom_line() +
ggtitle("Event Study - New York Times") +
scale_x_continuous(breaks = seq(-20, 40, by = 10), limits = c(-20, 40)) +
geom_line(aes(y = Max95), linetype = "dashed") +
geom_line(aes(y = Min95), linetype = "dotted") +
geom_vline(xintercept = -1, color = "red", size = 0.5) +
scale_y_reverse() +
labs(x = "Days From / Until Publication" , y = "Sales Rank Effect")
ylim(0.3, -0.6) +
theme_minimal()
ESNYT <- ggplot(reg7_agg, aes(x = NYT_elapse, y = Avg.Sales.rank)) +
geom_line() +
ggtitle("Event Study - New York Times") +
scale_x_continuous(breaks = seq(-20, 40, by = 10), limits = c(-20, 40)) +
geom_line(aes(y = Max95), linetype = "dashed") +
geom_line(aes(y = Min95), linetype = "dotted") +
geom_vline(xintercept = -1, color = "red", size = 0.5) +
scale_y_reverse() +
labs(x = "Days From / Until Publication" , y = "Sales Rank Effect") +
ylim(0.3, -0.6) +
theme_minimal()
ESNYT
reg7$residuals <- reg7$residuals - mean(reg7$residuals[which(dataUS$OTH_elapse == -1)])
reg7.1_agg <- aggregate(reg7$residuals, by = list(dataUS$OTH_elapse), FUN = mean)
colnames(reg7.1_agg) <- c("OTH_elapse", "Avg.Sales.rank")
reg7.1_agg <- reg7.1_agg %>%
mutate(Max95 = Avg.Sales.rank + (1.96*sd(Avg.Sales.rank)/ sqrt(length(reg7))),
Min95 = Avg.Sales.rank - (1.96*sd(Avg.Sales.rank) / sqrt(length(reg7))))
ESOTH <- ggplot(reg7.1_agg, aes(x = OTH_elapse, y = Avg.Sales.rank)) +
geom_line() +
ggtitle("Event Study - Other Magazines") +
scale_x_continuous(breaks = seq(-20, 40, by = 10), limits = c(-20, 40)) +
#  geom_line(aes(y = Max95), linetype = "dashed") +
#  geom_line(aes(y = Min95), linetype = "dotted") +
geom_vline(xintercept = -1, color = "red", size = 0.5) +
scale_y_reverse() +
ylim(0.5, -0.5) +
theme_minimal()
ESOTH
dataAdj <- data %>%
filter(((data$DBG == 0 & data$DCHI == 0 & data$DLAT == 0 & data$DWAPO == 0 & data$DWSJ == 0 & data$DNYT == 1) | data$DNYT == 0) & cno == 3)
ESNYTNew <- ggplot(reg8_agg, aes(x = NYT_elapse, y = Avg.Sales.rank)) +
geom_line() +
ggtitle("Adjusted Event Study - New York Times") +
scale_x_continuous(breaks = seq(-20, 40, by = 10), limits = c(-20, 40)) +
geom_line(aes(y = Max95), linetype = "dashed") +
geom_line(aes(y = Min95), linetype = "dotted") +
geom_vline(xintercept = -1, color = "red", size = 0.5) +
scale_y_reverse() +
ylim(0.3, -0.6) +
theme_minimal()
reg8 <- feols(lrank ~ L1.lrank + lpamzn + lreview + lR | canum, vcov = "hetero", data = dataAdj)
# 2. Mean-adjustment on NYT_elapse = -1.
reg8$residuals <- reg8$residuals - mean(reg8$residuals[which(dataAdj$NYT_elapse == -1)])
# 3. Aggregation
reg8_agg <- aggregate(reg8$residuals, by = list(dataAdj$NYT_elapse), FUN = mean)
colnames(reg8_agg) <- c("NYT_elapse", "Avg.Sales.rank")
reg8_agg <- reg8_agg %>%
mutate(Max95 = Avg.Sales.rank + (1.96*sd(Avg.Sales.rank)/ sqrt(length(reg8))),
Min95 = Avg.Sales.rank - (1.96*sd(Avg.Sales.rank) / sqrt(length(reg8))))
ESNYTNew <- ggplot(reg8_agg, aes(x = NYT_elapse, y = Avg.Sales.rank)) +
geom_line() +
ggtitle("Adjusted Event Study - New York Times") +
scale_x_continuous(breaks = seq(-20, 40, by = 10), limits = c(-20, 40)) +
geom_line(aes(y = Max95), linetype = "dashed") +
geom_line(aes(y = Min95), linetype = "dotted") +
geom_vline(xintercept = -1, color = "red", size = 0.5) +
scale_y_reverse() +
ylim(0.3, -0.6) +
theme_minimal()
ESNYTNew
ESNYT <- ggplot(reg7_agg, aes(x = NYT_elapse, y = Avg.Sales.rank)) +
geom_line() +
ggtitle("Event Study - New York Times") +
scale_x_continuous(breaks = seq(-20, 40, by = 10), limits = c(-20, 40)) +
geom_line(aes(y = Max95), linetype = "dashed") +
geom_line(aes(y = Min95), linetype = "dotted") +
geom_vline(xintercept = -1, color = "red", size = 0.5) +
scale_y_reverse() +
labs(x = "Days From / Until Publication" , y = "Sales Rank Effect") +
ylim(0.3, -0.6) +
theme_minimal()
ESNYT
star_elas_25 <- dataUS$B * (reg5$coefficients["lR"] +  reg5$coefficients["lrR"] * quantile(dataUS$lreview, probs = 0.25, na.rm = TRUE)) / (1 -  reg5$coefficients["L1.lrank"])
star_elas_50 <- dataUS$B * ( reg5$coefficients["lR"] +  reg5$coefficients["lrR"] * quantile(dataUS$lreview, probs = 0.5, na.rm = TRUE)) / (1 -  reg5$coefficients["L1.lrank"])
star_elas_75 <- dataUS$B * ( reg5$coefficients["lR"] +  reg5$coefficients["lrR"] * quantile(dataUS$lreview, probs = 0.75, na.rm = TRUE)) / (1 -  reg5$coefficients["L1.lrank"])
dataUS$star_elas_25 <- star_elas_25
A_B_params <- read_dta("A_B_params.dta")
library(haven)
A_B_params <- read_dta("A_B_params.dta")
A_B_params_bs <- read_dta("A_B_params_bs.dta")
pw_weekly <- read_dta("pw_weekly.dta")
sigma <- read_dta("sigma.dta")
dataUS <- merge(dataUS, A_B_params)
dataUS <- merge(dataUS, sigma)
star_elas_25 <- dataUS$B * (reg5$coefficients["lR"] +  reg5$coefficients["lrR"] * quantile(dataUS$lreview, probs = 0.25, na.rm = TRUE)) / (1 -  reg5$coefficients["L1.lrank"])
star_elas_50 <- dataUS$B * ( reg5$coefficients["lR"] +  reg5$coefficients["lrR"] * quantile(dataUS$lreview, probs = 0.5, na.rm = TRUE)) / (1 -  reg5$coefficients["L1.lrank"])
star_elas_75 <- dataUS$B * ( reg5$coefficients["lR"] +  reg5$coefficients["lrR"] * quantile(dataUS$lreview, probs = 0.75, na.rm = TRUE)) / (1 -  reg5$coefficients["L1.lrank"])
dataUS$star_elas_25 <- star_elas_25
dataUS$star_elas_50 <- star_elas_50
dataUS$star_elas_75 <- star_elas_75
price_elas_mean <- dataUS$B * reg5$coefficients["lpamzn"] / (1 - reg5$coefficients["L1.lrank"])
dataUS$price_elas_mean <- price_elas_mean
star_elas_mean <- dataUS$B * (reg5$coefficients["lR"] + reg5$coefficients["lrR"] * mean(dataUS$lreview)) / (1 - reg5$coefficients["L1.lrank"])
dataUS$star_elas_mean <- star_elas_mean
oth_1_10 <- dataUS$B *  reg5$coefficients["dothpost_3"] / (1 - reg5$coefficients["L1.lrank"])
dataUS$oth_1_10 <- oth_1_10
oth_11_20 <- dataUS$B *  reg5$coefficients["dothpost10_3"] / (1 - reg5$coefficients["L1.lrank"])
dataUS$oth_11_20 <- oth_11_20
nyt_1_5_not_rec <- dataUS$B * reg5$coefficients["dnytpost1_3"] / (1 - reg5$coefficients["L1.lrank"])
dataUS$nyt_1_5_not_rec <- nyt_1_5_not_rec
nyt_6_10_not_rec <- dataUS$B * reg5$coefficients["dnytpost6_3"] / (1 - reg5$coefficients["L1.lrank"])
dataUS$nyt_6_10_not_rec <- nyt_6_10_not_rec
nyt_11_20_not_rec <- dataUS$B * reg5$coefficients["dnytpost10_3"] / (1 - reg5$coefficients["L1.lrank"])
dataUS$nyt_11_20_not_rec <- nyt_11_20_not_rec
nyt_1_5_rec <- dataUS$B * reg5$coefficients["dnytpost1r_3"] / (1 - reg5$coefficients["L1.lrank"])
dataUS$nyt_1_5_rec <- nyt_1_5_rec
nyt_6_10_rec <- dataUS$B * reg5$coefficients["dnytpost6r_3"] / (1 - reg5$coefficients["L1.lrank"])
dataUS$nyt_6_10_rec <- nyt_6_10_rec
nyt_11_20_rec <- dataUS$B * reg5$coefficients["dnytpost10r_3"] / (1 - reg5$coefficients["L1.lrank"])
dataUS$nyt_11_20_rec <- nyt_11_20_rec
readRDS("other_only.RDS")
#US simulations
dataUS <- data %>%
filter(cno == 3) %>%
arrange(canum, ddate)
dataUS <- merge(dataUS, A_B_params)
dataUS <- merge(dataUS, sigma)
dataUS <- dataUS %>%
group_by(asin, genre) %>%
mutate(e1 = B * (reg5$coefficients["dnytpost1_3"] * dnytpost1_3 +
reg5$coefficients["dnytpost6_3"] * dnytpost6_3 +
reg5$coefficients["dnytpost10_3"] * dnytpost10_3 +
reg5$coefficients["dothpost_3"] * dothpost_3 +
reg5$coefficients["dothpost10_3"] * dothpost10_3 +
reg5$coefficients["dnytpost1r_3"] * dnytpost1r_3 +
reg5$coefficients["dnytpost6r_3"] * dnytpost6r_3 +
reg5$coefficients["dnytpost10r_3"] * dnytpost10r_3) / (1 - reg5$coefficients["L1.lrank"]),
q1 = A / (exp((B*lrank) - e1)),
q = A / (exp((B*lrank))))
dataUS$gamma1 <- 0
dataUS$gamma1 <- ifelse((!is.na(dataUS$lreview) & !is.na(dataUS$lR)),  dataUS$B * (dataUS$lR + dataUS$lreview * reg5$coefficients["lR"]) / (1 - reg5$coefficients["L1.lrank"]))
dataUS <- dataUS %>%
mutate(alpha1 = B*(reg5$coefficients["lpamzn"]) / (1-(reg5$coefficients["L1.lrank"])))
dataUS <- dataUS %>%
group_by(asin) %>%
mutate(maxdate = max(ddate), avgR = mean(R))
dataUS2 <- dataUS %>%
filter(ddate == maxdate)
reg9 <- feols(avgR ~ numbooks + gno | pubno, data = dataUS2)
Rhat <- predict(reg9)
lRhat <- log(Rhat)
dataUS2 <- dataUS2 %>%
mutate(DOTH = ifelse(!is.na(OTHDATE), 1, 0)) %>%
rename(p = pamzn)
# Zusammenfassung der Variablen basierend auf den Gruppierungen von asin und genre
summary_data_Sim <- dataUS2 %>%
group_by(asin, genre) %>%
summarise(
sum_q = sum(q),
sum_q1 = sum(q1),
mean_e1 = mean(e1),
mean_gamma1 = mean(gamma1),
mean_alpha1 = mean(alpha1),
mean_p = mean(p),
mean_lR = mean(lR),
mean_lRhat = mean(lRhat),
mean_R = mean(R),
mean_Rhat = mean(Rhat),
mean_sigma = mean(sigma),
mean_avgR = mean(avgR),
max_DNYT = max(DNYT),
max_1_5 = max(dnytpost1_3),
max_6_10 = max(dnytpost6_3),
max_11_20 = max(dnytpost10_3),
max_1_5_rec = max(dnytpost1r_3),
max_6_10_rec = max(dnytpost6r_3),
max_11_20_rec = max(dnytpost10r_3),
max_1_10 = max(dothpost_3),
max11_20 = max(dothpost10_3),
max_DOTH = max(DOTH),
max_DUSAT = max(DUSAT),
mean_lreview = mean(lreview),
mean_drecommended = mean(drecommended)
)
# Speichern des zusammengefassten Datensatzes in einer neuen Datei
write.csv(summary_data_Sim, "quantity_us_simulations.csv", row.names = FALSE)
collapsed_data <- summary_data_Sim %>%
group_by(asin) %>%
summarize(
mean_DNYT = mean(max_DNYT),
mean_DOTH = mean(max_DOTH),
mean_drecommend = mean(mean_drecommended),
mean_q = mean(sum_q),
mean_q1 = mean(sum_q1)
)
colnames(collapsed_data) <- c("asin", "DNYT", "DOTH", "drecommended", "q", "q1")
# Berechnung der Veränderung
collapsed_data$change <- 100 * ((collapsed_data$q / collapsed_data$q1) - 1)
# Berechnung der Mittelwerte für verschiedene Kombinationen von DNYT, DOTH und drecommend
other_only <- mean(collapsed_data$change[collapsed_data$DNYT == 0 & collapsed_data$DOTH == 1])
nyt_not_rec_only <- mean(collapsed_data$change[collapsed_data$DNYT == 1 & collapsed_data$DOTH == 0 & collapsed_data$drecommended == 0])
nyt_rec_only <- mean(collapsed_data$change[collapsed_data$DNYT == 1 & collapsed_data$DOTH == 0 & collapsed_data$drecommended == 1])
both_not_rec <- mean(collapsed_data$change[collapsed_data$DNYT == 1 & collapsed_data$DOTH == 1 & collapsed_data$drecommended == 0])
both_rec <- mean(collapsed_data$change[collapsed_data$DNYT == 1 & collapsed_data$DOTH == 1 & collapsed_data$drecommended == 1])
nytoverall <- mean(collapsed_data$change[collapsed_data$DNYT == 1])
overall <- mean(collapsed_data$change[collapsed_data$DNYT + collapsed_data$DOTH >= 1])
summary_data <- data.frame(Effects = c(mean(price_elas_mean), mean(star_elas_25), mean(star_elas_50), mean(star_elas_75), mean(star_elas_mean), mean(nyt_1_5_not_rec), mean(nyt_6_10_not_rec), mean(nyt_11_20_not_rec), mean(nyt_1_5_rec), mean(nyt_6_10_rec), mean(nyt_11_20_rec), mean(oth_1_10), mean(oth_11_20), other_only, nyt_not_rec_only, nyt_rec_only, both_not_rec, both_rec, overall))
row.names(summary_data) = c("Price Elasticity", "Star Elasticity 25%", "Star Elasticity 50%", "Star Elasticity 75%", "Star Elasticity Overall", "NYT 1-5 Days", "NYT 6-11 Days", "NYT 11-20 Days", "NYT 1-5 Days rec", "NYT 6-11 Days rec", "NYT 11-20 Days rec", "OTH 1-10 Days", "OTH 11-20 Days", "Only other Magazines", "Only NYT not recommended", "Only NYT recommended", "Both not recommended", "Both recommended", "Average")
summary_data %>%
kbl(caption = "Elasticities") %>%
kable_paper("striped", full_width = TRUE) %>%
pack_rows("Percent effect of review on annual q", 14, 19) %>%
kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))
library(RTutor)
library(modelsummary)
library(dplyr)
library(yaml)
library(xfun)
library(tidyverse)
library(kableExtra)
library(grid)
library(gridExtra)
#Set Working Directory
setwd("D:/Universitaet Ulm Unterlagen/Bachelorarbeit/The-Impact-Of-Reviews-And-Ratings-On-Bookmarket")
# Set problem set's name
ps.name = "The Impacts of reviews and Ratings on Book Market"; sol.file = paste0(ps.name,"_sol.Rmd")
# character vector of all required packages in the problem set
libs = c("ggplot2", "tidyverse", "kableExtra", "modelsummary")
# Create Problem Set
create.ps(sol.file=sol.file, user.name = NULL, ps.name=ps.name,libs=libs,stop.when.finished=FALSE, addons = "quiz")
#open problem set in web browser
show.ps(ps.name,launch.browser=TRUE, auto.save.code=FALSE, sample.solution=FALSE, load.sav=FALSE,  is.solved=FALSE)
#< task_notest
#load the package "ggplot2"
library(ggplot2)
demand <- c(2, 1.5, 1, 0.5, 0)
xAxis <- c(0, 1,2,3,4)
supply <- c(0, 0.5, 1, 1.5, 2)
xGroup <- c(1, 1, 1, 1, 1)
DatasetTest <- data.frame(Price = demand, Quantity = xAxis, Supply = supply, Group = xGroup)
#Read in fdemandsupply
fdemandsupply <- readRDS("fdemandsupply.RDS")
fdemandsupplyfinal <- fdemandsupply  +
geom_text(aes(x=0.5, y=1.83, label = "Demand"), color = "Black", angle = 329, size= 4, alpha=0.1) +
geom_text(aes(x=3.35, y=1.78, label = "Supply"), color = "Black", angle = 31, size= 4, alpha=0.1) +
theme_bw() +
labs(title = "How is Pre-Purchase Information related to Welfare?",
x = "Quantity",
y = "Price") +
scale_x_continuous(labels = c("0", "", "Q*", "", "")) +
scale_y_continuous(labels = c("0", "", "P*", "", "")) +
theme(
panel.grid.minor=element_blank(),plot.background=element_blank())
fdemandsupplyfinal
#>
View(fdemandsupply)
library(RTutor)
library(modelsummary)
library(dplyr)
library(yaml)
library(xfun)
library(tidyverse)
library(kableExtra)
library(grid)
library(gridExtra)
#Set Working Directory
setwd("D:/Universitaet Ulm Unterlagen/Bachelorarbeit/The-Impact-Of-Reviews-And-Ratings-On-Bookmarket")
# Set problem set's name
ps.name = "The Impacts of reviews and Ratings on Book Market"; sol.file = paste0(ps.name,"_sol.Rmd")
# character vector of all required packages in the problem set
libs = c("ggplot2", "tidyverse", "kableExtra", "modelsummary")
# Create Problem Set
create.ps(sol.file=sol.file, user.name = NULL, ps.name=ps.name,libs=libs,stop.when.finished=FALSE, addons = "quiz")
library(RTutor)
library(modelsummary)
library(dplyr)
library(yaml)
library(xfun)
library(tidyverse)
library(kableExtra)
library(grid)
library(gridExtra)
#Set Working Directory
setwd("D:/Universitaet Ulm Unterlagen/Bachelorarbeit/The-Impact-Of-Reviews-And-Ratings-On-Bookmarket")
# Set problem set's name
ps.name = "The Impacts of reviews and Ratings on Book Market"; sol.file = paste0(ps.name,"_sol.Rmd")
# character vector of all required packages in the problem set
libs = c("ggplot2", "tidyverse", "kableExtra", "modelsummary")
# Create Problem Set
create.ps(sol.file=sol.file, user.name = NULL, ps.name=ps.name,libs=libs,stop.when.finished=FALSE, addons = "quiz")
